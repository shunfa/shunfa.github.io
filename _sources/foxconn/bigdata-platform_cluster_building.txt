=========================
海量資料運算平台建置
=========================

* OS: Ubuntu 12.04
* Java: 
* MySQL: 
 * `sudo apt-get install libmysql-java`
* phpMyAdmin: 
* Hadoop:
* HBase: 
* Zookeeper:

**lamp快速安裝：sudo tasksel install lamp-server**


目前架構(2014/02編輯)
==========================

.. csv-table:: 機器表
   :header: "Hostname", "ip"
   :widths: 20, 20

   "hadoop-master", "192.168.100.100" 
   "hadoop-slave1", "192.168.100.101"
   "ThinkPad-X200", "192.168.100.200"

新增節點步驟
---------------

1) 使用image還原至新主機
#) 修改主機的hostname
#) 編輯/etc/hosts
#) 同步/etc/hosts, hadoop slave, zookeeper and hbase，若zookeeper變成單數，則需修改HBase中的zookeeper設定
#) 清空 /var/hadoop
#) 啟動


修改IP時，需注意的狀況
============================

需求：Hadoop運算節點有可能因為環境變動而修改IP，修改IP會造成Namenode與Datanode無法溝通，造成HDFS無法讀取，以下是預防及解決方式：

1) 預防：hadoop及hbase設定時，盡量避免使用ip方式設定，透過hostname設定可以完全避免掉此一狀況。
#) 補救：修改namespace及datanode mapping的IP，檔案及目錄名稱如下(修改相關的對應IP即可)：
 * /var/hadoop/user-hadoop/dfs/data/current/VERSION
 * /var/hadoop/user-hadoop/dfs/data/current/BP-1359720127-hadoop-master-1390886984124
 * /var/hadoop/user-hadoop/dfs/name/current/VERSION
3) 砍掉重練：這是最快的方法，適用於HDFS上沒有想要留下的資料，直接清空/var/hadoop目錄下的所有資料，重新format

FSCK 確認 HDFS健康狀況
----------------------------

* 檢查健康狀況
 * `hadoop fsck /`
* 修復：
 * `hadoop fsck -delete /`
 * `hadoop fsck -move /`



TODO
========

* [v] master clone image
* [v] master resize
* [v] restore to slaves
* [redo] /var/ 分割區


*last update: 2014-02-08*

